{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyBot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPd2h9PzZO26jyc22lj/pT3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErrorOfTheGeneration/pyBotTG_google/blob/main/pyBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random   # для рандомных ответов из словаря ответов\n",
        "import nltk     # для работы с опечатками\n",
        "import json\n"
      ],
      "metadata": {
        "id": "6Ni3H01aYMXC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# далее обозначено зачем 1-я библиотека. 2-ю погуглить\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "fmUq-f45LOyU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FqRWgfSxuM5E"
      },
      "outputs": [],
      "source": [
        "with open('/content/BIG_BOT_CONFIG.json', 'r') as f:  # json для хранения словарей (поискать справку)\n",
        "  BOT_CONFIG = json.load(f)\n",
        "# словарь словарей. Нужен нам для того, чтобы определять, что хочет пользователь\n",
        "# и соттветствующе отвечать ему\n",
        "# BOT_CONFIG = {\n",
        "#     'intents': {\n",
        "#         'hello': {\n",
        "#             'examples': ['Привет!', 'Хай', 'Добрый день', 'здравствуй', 'здравствуйте',\n",
        "#                          'приветик', 'здрасте', 'здорова'], # примеры приветствия\n",
        "#             'resposes': ['Доброго времени суток', 'Привет', 'приветствую', 'Здравствуй']  #ответы бота\n",
        "#         },\n",
        "#         'bye': {\n",
        "#             'examples': ['Пока', 'До свидания', 'Увидимся', 'Счастливо', 'до новых встреч'],\n",
        "#             'resposes': ['Счастливо', 'Хаюхай', 'Удачного дня', 'Приходите ещё', 'Будьте здоровы', 'До новых встреч!']\n",
        "#         }\n",
        "#     }\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(BOT_CONFIG['intents'])"
      ],
      "metadata": {
        "id": "dx3E_vu3ICxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def clean(text): #принимает текст, возвращает чищенный текст ниж.регистр и без знаков препинания\n",
        "  return ''.join([simbol for simbol in text.lower() if simbol in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '])\n",
        "\n",
        "# функция match нужна для того, чтобы бот не был чувствителен к регистру или знакам препинания\n",
        "\n",
        "# nltk позволяет вычислять расстояние Ливенштейна \n",
        "# между строками, т.е. кол-во редакторских исправлений, \n",
        "# чтобы из одного слова получить другое\n",
        "def match(example, text):      \n",
        "  return nltk.edit_distance(clean(text),clean(example)) / len(example) < 0.4\n",
        "\n",
        "# пробегаем по всему нашему словарю и ищем, в какой интент (намерение) попадает\n",
        "# введённое пользователем слово\n",
        "def get_intent(text):\n",
        "  for intent, value in BOT_CONFIG['intents'].items():\n",
        "    for example in value['examples']:\n",
        "      if match(example, text):\n",
        "        return random.choice(value['resposes'])\n",
        "  return'Я не понимаю, чего от меня хотят'"
      ],
      "metadata": {
        "id": "cdPVh9GKC-T_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = input()            # просим пользователя ввести\n",
        "answer = get_intent(question)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "qxhrTA4TDZb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while question != 'выход':\n",
        "  question = input()            \n",
        "  answer = get_intent(question)\n",
        "  print(answer)"
      ],
      "metadata": {
        "id": "IRUYDKBSAbJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "возьмем библиотеку scikit-learn. В ней есть векторайзеры - специальные объекты,\n",
        "которые превращают тексты в вектора"
      ],
      "metadata": {
        "id": "GZH2gvbWLNGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Сделаем дата-сет (набор данных для машинного обучения) из файла BOT_CONFIG\n",
        "# нам нужны пары объект-ответ\n",
        "# икс - для объектов обучающей выборки. там - вектора всех текстов \n",
        "# игрек - ответы для всех векторов, записанные в том же самом порядке\n",
        "# X = [v1, v2, v3]\n",
        "# Y = [int1, int2, int3]"
      ],
      "metadata": {
        "id": "yPOYIgO3Pc0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for intent, value in BOT_CONFIG['intents'].items():\n",
        "  examples = set(value['examples']) # *1\n",
        "  X = X + value['examples']\n",
        "  y = y + [intent] * len(value['examples'])\n",
        "# *1 преобразуем список в множество на случай неуникальных экземплс, чтобы не \n",
        "# не затруднять обучение машине. Теперь элементы не повторяются"
      ],
      "metadata": {
        "id": "PiP_nn4rQlnW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Векторизуем дата-сет. Эти вектора можно подавать на вход модели\n",
        "vectorizer = TfidfVectorizer() # ngram_range - с помощью этого пар-ра работаем со словосочет.\n",
        "X_transformed = vectorizer.fit_transform(X)"
      ],
      "metadata": {
        "id": "B7up5b34Rhjw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# теперь мы можем делать предсказания (predict)\n",
        "# text = 'пока'\n",
        "# classifier.predict(vectorizer.transform([text]))"
      ],
      "metadata": {
        "id": "cWIG2magajbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заметим что векторайзер не зависит от регистра. Любому тексту он может поставить в соответствие вектор. И всем текстам надо поставить вектора, чтобы их показать модели машинного обучения, а она на основе векторов попытается понять, как зависит класс текста, намерение пользователя, от того, на каких местах какие числа в этих векторах располагаются.\n"
      ],
      "metadata": {
        "id": "DlF6MgosNVpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нам нужно замерить качетво классификации. Ибо вдруг на этих 2х примерах правильно работает, а в остальных случаях нет.\n",
        "Кач-во классификации замеряют так:берут большую выборку (наше X_transformed), делят ее вкакой-то пропорции (например 80% на 20%, или 66% и 34%) и на  2/3 обучают модель, а тестируют на 1/3. Это делают, чтобы понять, поняла ли модель общий закон \"...\". Когда модель запоминает некоторые конкретные признаки, которые не обобщаются,и которые будут бесполезны за пределами этого дата-сета,называется переобучением. Чтобы его избежать, исп. разделение выборки. Для удобного разделения выборки тоже есть функция в сайкет лёрне sklearn.model_selection.train_test_split"
      ],
      "metadata": {
        "id": "Tmom00Qy1fnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В train_test_split надо передать саму выборку X = X_transformed, "
      ],
      "metadata": {
        "id": "UOrOSLm-4xO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "fiLZgSzV3QnK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = RandomForestClassifier()\n",
        "classifier.fit(X_train, y_train) # обучаем"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVFZjx7j5IuJ",
        "outputId": "21ecba9d-2891-47c6-8241-35a35804d6fc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# можем посмотреть, какого результата мы добились на тестовой выборке(отложенной)\n",
        "# т.е. которую мы отложили чтобы замерить качество. Чем больше обучающих примеров, \n",
        "# тем выше будет качество\n",
        "classifier.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTEZcHBX5qUn",
        "outputId": "6fc0550a-2eb0-463c-aa77-5a15083d753a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.score(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0TjAivf9KGe",
        "outputId": "bb87ec42-dd34-4e1e-dfe9-97a08c74028d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}