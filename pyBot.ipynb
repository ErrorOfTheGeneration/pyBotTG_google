{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyBot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSWAj4V5fSx/zRUGaOZ9kb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErrorOfTheGeneration/pyBotTG_google/blob/main/pyBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random   # для рандомных ответов из словаря ответов\n",
        "import nltk     # для работы с опечатками\n",
        "import json\n"
      ],
      "metadata": {
        "id": "6Ni3H01aYMXC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# далее обозначено зачем 1-я библиотека. 2-ю погуглить\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "fmUq-f45LOyU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FqRWgfSxuM5E"
      },
      "outputs": [],
      "source": [
        "with open('/content/BIG_BOT_CONFIG.json', 'r') as f:  # json для хранения словарей (поискать справку)\n",
        "  BOT_CONFIG = json.load(f)\n",
        "# словарь словарей. Нужен нам для того, чтобы определять, что хочет пользователь\n",
        "# и соттветствующе отвечать ему\n",
        "# BOT_CONFIG = {\n",
        "#     'intents': {\n",
        "#         'hello': {\n",
        "#             'examples': ['Привет!', 'Хай', 'Добрый день', 'здравствуй', 'здравствуйте',\n",
        "#                          'приветик', 'здрасте', 'здорова'], # примеры приветствия\n",
        "#             'resposes': ['Доброго времени суток', 'Привет', 'приветствую', 'Здравствуй']  #ответы бота\n",
        "#         },\n",
        "#         'bye': {\n",
        "#             'examples': ['Пока', 'До свидания', 'Увидимся', 'Счастливо', 'до новых встреч'],\n",
        "#             'resposes': ['Счастливо', 'Хаюхай', 'Удачного дня', 'Приходите ещё', 'Будьте здоровы', 'До новых встреч!']\n",
        "#         }\n",
        "#     }\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(BOT_CONFIG['intents'])"
      ],
      "metadata": {
        "id": "dx3E_vu3ICxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def clean(text): #принимает текст, возвращает чищенный текст ниж.регистр и без знаков препинания\n",
        "  return ''.join([simbol for simbol in text.lower() if simbol in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '])\n",
        "\n",
        "# функция match нужна для того, чтобы бот не был чувствителен к регистру или знакам препинания\n",
        "\n",
        "# nltk позволяет вычислять расстояние Ливенштейна \n",
        "# между строками, т.е. кол-во редакторских исправлений, \n",
        "# чтобы из одного слова получить другое\n",
        "def match(example, text):      \n",
        "  return nltk.edit_distance(clean(text),clean(example)) / len(example) < 0.4\n",
        "\n",
        "# пробегаем по всему нашему словарю и ищем, в какой интент (намерение) попадает\n",
        "# введённое пользователем слово\n",
        "def get_intent(text):\n",
        "  for intent, value in BOT_CONFIG['intents'].items():\n",
        "    for example in value['examples']:\n",
        "      if match(example, text):\n",
        "        return random.choice(value['resposes'])\n",
        "  return'Я не понимаю, чего от меня хотят'"
      ],
      "metadata": {
        "id": "cdPVh9GKC-T_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = input()            # просим пользователя ввести\n",
        "answer = get_intent(question)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "qxhrTA4TDZb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while question != 'выход':\n",
        "  question = input()            \n",
        "  answer = get_intent(question)\n",
        "  print(answer)"
      ],
      "metadata": {
        "id": "IRUYDKBSAbJx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "возьмем библиотеку scikit-learn. В ней есть векторайзеры - специальные объекты,\n",
        "которые превращают тексты в вектора"
      ],
      "metadata": {
        "id": "GZH2gvbWLNGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer"
      ],
      "metadata": {
        "id": "J0wB0h3hL8kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сделаем дата-сет (набор данных для машинного обучения) из файла BOT_CONFIG\n",
        "# нам нужны пары объект-ответ\n",
        "# икс - для объектов обучающей выборки. там - вектора всех текстов \n",
        "# игрек - ответы для всех векторов, записанные в том же самом порядке\n",
        "# X = [v1, v2, v3]\n",
        "# Y = [int1, int2, int3]"
      ],
      "metadata": {
        "id": "yPOYIgO3Pc0e"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "for intent, value in BOT_CONFIG['intents'].items():\n",
        "  examples = set(value['examples']) # *1\n",
        "  X = X + value['examples']\n",
        "  Y = Y +[intent] * len(value['examples'])\n",
        "# *1 преобразуем список в множество на случай неуникальных экземплс, чтобы не \n",
        "# не затруднять обучение машине. Теперь элементы не повторяются"
      ],
      "metadata": {
        "id": "PiP_nn4rQlnW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Векторизуем дата-сет. Эти вектора можно подавать на вход модели\n",
        "X_transformed = vectorizer.fit_transform(X)"
      ],
      "metadata": {
        "id": "B7up5b34Rhjw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создадим объект форест классифаер. Фит - обучить\n",
        "classifier = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "erQIeVaPZplH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# обучим объект на X_transformed и Y. То есть ему надо дать вектора и ответ на них.\n",
        "# Он попробует найти зависимость, чтобы для новых векторов уж езнать ответ\n",
        "classifier.fit(X_transformed, Y)"
      ],
      "metadata": {
        "id": "RH1x0LWKVa_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# теперь мы можем делать предсказания (predict)\n",
        "classifier.predict(vectorizer.transform(['Доброго времени суток']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "cWIG2magajbu",
        "outputId": "cb63e887-c868-43cd-baa9-62c23b28e87c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-f8dcdabca182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# теперь мы можем делать предсказания (predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Доброго времени суток'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: X has 6 features, but RandomForestClassifier is expecting 16 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтобы что-то векторизовать, надо понимать, о каком словаре идет речь.\n",
        "# Значит, сначала векторайзер нужно обучить. Для обучения ему нужно несколько текстов\n",
        "vectorizer.fit(['Доброго времени суток', 'Привет', 'приветствую', 'Здравствуй'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Unh4QFtUMGx7",
        "outputId": "cdff808d-267e-4510-ef58-5c498b5f8e25"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заметим что векторайзер не зависит от регистра. Любому тексту он может поставить в соответствие вектор. И всем текстам надо поставить вектора, чтобы их показать модели машинного обучения, а она на основе векторов попытается понять, как зависит класс текста, намерение пользователя, от того, на каких местах какие числа в этих векторах располагаются.\n"
      ],
      "metadata": {
        "id": "DlF6MgosNVpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.transform(['Доброго времени суток', 'Привет', 'приветствую', 'Здравствуй'])[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlunxekkM-Lr",
        "outputId": "57696b30-d9e8-4469-e0b2-3f750bf4dfb2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}